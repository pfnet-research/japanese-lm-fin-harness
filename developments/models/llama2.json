[
    {
        "model": "meta-llama/Llama-2-7b-hf",
        "model_args": [],
        "memory_Gi": 32,
        "n_gpu": 1,
        "gpu_vram_gb": 24,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-7b-chat-hf",
        "model_args": [],
        "memory_Gi": 32,
        "n_gpu": 1,
        "gpu_vram_gb": 24,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-13b-hf",
        "model_args": [],
        "memory_Gi": 64,
        "n_gpu": 1,
        "gpu_vram_gb": 80,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-13b-chat-hf",
        "model_args": [],
        "memory_Gi": 64,
        "n_gpu": 1,
        "gpu_vram_gb": 80,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-70b-hf",
        "model_args": [
            "use_accelerate=True",
            "device_map_option=auto"
        ],
        "memory_Gi": 128,
        "n_gpu": 2,
        "gpu_vram_gb": 80,
        "require_hf_login": true
    },
    {
        "model": "meta-llama/Llama-2-70b-chat-hf",
        "model_args": [
            "use_accelerate=True",
            "device_map_option=auto"
        ],
        "memory_Gi": 128,
        "n_gpu": 2,
        "gpu_vram_gb": 80,
        "require_hf_login": true
    }
]